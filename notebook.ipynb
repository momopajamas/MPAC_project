{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c626feae-933c-4be9-a3a2-cc38602e357d",
   "metadata": {},
   "source": [
    "# I. Introduction\n",
    "\n",
    "With the upsurge in Islamophobia rhetoric in recent months that is starkly reminiscient of a post-9/11 climate in the US and the West, the Muslim Public Affairs Committee (MPAC) has tasked the Center for Security, Technology, and Policy (CSTP) with locating trends within this discourse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d023be5b-5ee0-4326-a4f6-55f6d150861c",
   "metadata": {},
   "source": [
    " ## Problem Understanding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634fd33d-32ae-4494-8b16-07f2cfd37b01",
   "metadata": {},
   "source": [
    "The goal of this project is to identify dominant themes and patterns underpinning Islamophobic rhetoric in order to better inform research and policy recommendations. Specifically, this project focuses on extracting actionable insights by identifying recurring language patterns, narrative frames, and potential changes in discourse that can support effective advocacy, monitoring, and community safety responses. To accomplish this, we analyze a dataset of public posts from X (formerly Twitter) from a variety of users. \n",
    "\n",
    "Because large-scale manual review of social media content is not feasible, this project also includes a lightweight machine learning component designed to support scalable detection. First, we build a baseline NLP classifier that can distinguish between Islamophobic and non-Islamophobic tweets. Then, using the tweets identified as Islamophobic, we apply thematic analysis (e.g., clustering/topic discovery) to surface the most common narratives and rhetorical patterns present in the dataset. This combined approach supports both detection (what content should be flagged for review) and understanding (what narratives are driving the discourse).\n",
    "\n",
    "#### Defining Islamophobia\n",
    "\n",
    "Islamophobia as a concept can encompass a variety of rhetoric, depending on the definition one uses. For the purposes of this project, we will use the definition of Islamophobia used by the [Bridge Initiative at Georgetown University](https://bridge.georgetown.edu/about-us/what-is-islamophobia/), which posits that \"*Islamophobia is an extreme fear of and hostility toward Islam and Muslims which often leads to hate speech, hate crimes, as well as social and political discrimination.*\"\n",
    "\n",
    "We use this definition in order to limit the scope of the investigation specifically to rhetoric that echos fears and hatred of Islam and Muslims specifically. In order to maintain focus, tweets that are critical or antagonistic to Muslim-majority states, for example, would only be considered Islamophobic if the rhetoric used directly or implicitly attacks Islam as a religion or Muslims as a people.\n",
    "\n",
    "### Project Scope\n",
    "- The dataset consists of 1,619 tweets collected from X.\n",
    "- The project creates a small, high-confidence manually labeled subset to train and evaluate a baseline classifier.\n",
    "- The dataset includes a small set of pre-labeled Islamophobic tweets (~90), which are treated as high-confidence positive examples. A small comparison set of non-Islamophobic tweets is created through targeted sampling and lightweight manual review to enable training and evaluation.\n",
    "- The modeling approach prioritizes interpretability and speed, using traditional NLP features (e.g., TF-IDF) and linear models rather than computationally expensive deep learning approaches.\n",
    "- After classification, the subset of Islamophobic tweets is used to perform theme discovery, producing interpretable clusters/topics supported by representative examples and key terms.\n",
    "- Due to the sensitive nature of the domain and the risk of harm from misclassification, the classifier is framed as a decision-support tool rather than an automatic enforcement system.\n",
    "\n",
    "### Success Criteria\n",
    "Success for this project can be measured by answering three questions:\n",
    "\n",
    "**1. Is the classifier functional and reliable enough to support triage?**\n",
    "- Performance will be evaluated using a confusion matrix and metrics such as precision, recall, and F1-score, with a particular emphasis on precision to reduce harmful false positives.\n",
    "\n",
    "**2. Did we learn something real, clear, and repeatable about the discourse?**\n",
    "- Thematic outputs should produce coherent categories of Islamophobic rhetoric (e.g., dehumanization, collective blame, exclusionary policy narratives, conspiracy framing) supported by representative tweets and distinguishing keywords.\n",
    "\n",
    "**4. Can the insights inform real decisions?**\n",
    "- Findings should translate into concrete, stakeholder-relevant outputs such as narrative summaries, ‚Äúwatchlist‚Äù language patterns, and recommendations that can inform policy memos, rapid response, or platform monitoring strategies.\n",
    "\n",
    "### Limitations & Ethics\n",
    "Islamophobia detection is highly context-dependent and can involve sarcasm, coded language, and quotation, making the task difficult even for human reviewers. Because the dataset does not include ground-truth labels, this project relies on a small manually labeled subset, which introduces subjectivity and may not reflect all language patterns in the full dataset. The classifier may also produce false positives when tweets mention Islam or Muslims in neutral or advocacy contexts. For these reasons, the model should be treated as a decision-support tool for triage rather than an automatic enforcement mechanism. A production-ready version would require larger labeled data, multiple annotators, and additional bias/fairness evaluation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4def5b5-97f4-4c18-a13b-81765b727851",
   "metadata": {},
   "source": [
    "# II. Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f98998-ef5b-483e-af8c-0f43ad6d262b",
   "metadata": {},
   "source": [
    "This dataset contains 1,619 public posts from X (formerly Twitter). Each row represents a single post and includes the post text, metadata about the author account, and engagement metrics. The data is intended to support analysis of Islamophobic discourse by enabling both language-based analysis (what is being said) and impact-based analysis (how widely it spreads).\n",
    "\n",
    "### Features\n",
    "- `Date`: Timestamp associated with the post. This allows trend analysis over time (e.g., spikes in activity or engagement).\n",
    "- `X Accounts`: The username or account identifier that published the post. This can be used to assess repetition, concentration of posting behavior, or high-volume accounts.\n",
    "- `Post Link`: Direct URL to the post for auditing and transparency.\n",
    "- `Post Text`: The main content of the tweet. This is the primary input feature for NLP tasks such as classification and theme discovery.\n",
    "- `Retweets` / `Comments` / `Likes` / `Bookmarks` / `Views`: Engagement metrics that approximate reach and amplification. Views represent the broadest measure of exposure, while retweets and bookmarks may indicate stronger forms of engagement.\n",
    "- `Custom Reports`: While this column is mostly empty, around 90 or so entries are marked as 'Islamophobic.' We will consider these entries as high-confidence labels and use them as a starting point to train our classifier.\n",
    "- `Quick Notes`/ `Legistlative Tracker`/ `Workflow`:  These are almost entirly empty, and the few entries contain nothing of value for our purposes, and we will need to cut these to clean our dataset.\n",
    "\n",
    "This dataset supports three core types of analysis:\n",
    "\n",
    "**1. Classification**: Using the post text to train a classifier that can triage harmful content.\n",
    "\n",
    "**2. Topic Modeling**: Identifying recurring narratives and language patterns within Islamophobic tweets (e.g., stereotypes, collective blame, exclusionary rhetoric).\n",
    "\n",
    "**3. Impact Analysis**: Using engagement metrics, especially views and retweets, to understand which narratives are most amplified and hold higher degrees of salience, and therefore may pose greater public influence or harm.\n",
    "\n",
    "### Quality Considerations\n",
    "\n",
    "Several quality issues are present in this dataset:\n",
    "\n",
    "- Missing or inconsistent labels: The dataset does not appear to have complete, standardized annotation fields. Some rows may contain partial labeling information, while most remain unlabeled.\n",
    "- Context loss: Tweets are short and often depend on context (threads, quotes, sarcasm, or external links or links to other tweets). This creates ambiguity when interpreting intent.\n",
    "- Noise in text: Tweet text may include URLs, mentions (@user), hashtags, emojis, or formatting artifacts that require preprocessing.\n",
    "- Engagement bias: Views and engagement are influenced by account size, virality dynamics, and platform algorithms, not only the content itself, so they should be interpreted as approximate impact signals rather than direct measures of harm.\n",
    "- Sampling bias: The dataset may not represent the full spectrum of Twitter discourse. It may be shaped by how the tweets were collected (search terms, accounts, timeframe).\n",
    "\n",
    "Additionally, the scope of this project and the nature of this dataset combined to create a number of limitations:\n",
    "- Our focus on identifying Islamophobia in particular leads us to exclude rhetoric containing other forms of hate and extremism, such as anti-Hindu or antisemitic rhetoric, which can often emanate from the same source or utilize overlapping forms of rhetoric.\n",
    "- Some tweets are antagonostic towards ethnicities or countries, and do not constitute Islamophobia in the strict sense we outlined above.\n",
    "- A large portion of the Islamophobic tweets present address particular social or political situations, such as controversies over mosques in Texas or the alleged fraud allegations of Somalis in Minnesota, which could potentially limit the extent of generalizability of identified themes.\n",
    "- The vast majority of the tweets deal with the the US context specifically, which could limit the transnational dimensions of Islamophobia.\n",
    "\n",
    "### Assumptions\n",
    "\n",
    "To keep the project feasible in a short timeline, the project assumes the following:\n",
    "\n",
    "- The post text contains enough signal to differentiate Islamophobic from non-Islamophobic content at a baseline level.\n",
    "- A small high-confidence labeled subset can provide enough ground truth to evaluate a lightweight baseline model.\n",
    "- The classified tweets can be clustered to extrect recurring themes and trends present within online Islamophobic discourse that can be generalized.\n",
    "\n",
    "### Model Selection\n",
    "\n",
    "For efficiency, we will deploy two models and assess how they perform on training and test data Both models will incorporate **Term Frequency-Inverse Document Frequency (TF-IDF)**, which will be useful in determining the relative significance of terms used across the content under `Post Text` by weighing the frequency of the appearance of those terms within a tweet against their relative rarity across all tweets in the dataset.\n",
    "\n",
    "1. `Logistic Regression`: This will be our baseline model as it is strong in text classification and relatively quick to train. The probabilities given by this model will potentially be useful for threshold tuning, and can provide us with the top words driving predictions.\n",
    "2. `LinearSVM`: This model excels at high-dimensional sparse text, and is likewise quick to train and robust.\n",
    "\n",
    "### Metrics\n",
    "\n",
    "For our purposes of narrative and trend analysis, **False Positives are more harmful than False Negatives**. This is because, while it would be unfortunate to mistakenly classify tweets as not Islamophobic when they actually are, the impact of this misclassification on our trend analysis would be minimized by the fact that, according to our assumptions, there are trends and recurring themes across these tweets. However, it would be far more detrimental to our analysis if our 'bucket' of Islamophobic tweets were polluted by tweets that are not Islamophobic, as this would distort the themes we extract and the conclusions we draw from them.\n",
    "\n",
    "Therefore, we will be using **Precision** as our primary metric of success, as this evaluates our ability to **keep False Positives out** and generate a high-confidence subset for analysis. In other words, it measures how 'pure' our Islamophobic bucket of tweets is, ensuring that the themes we extract are more cohesive and accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f5bca7-eb93-4533-a89c-fb25d4766460",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78df8caf-6e01-4df3-aeb9-3dc43efa3298",
   "metadata": {},
   "source": [
    "Several steps need to be taken before we are able to begin modeling and analyzing the data.\n",
    "\n",
    "First, since the dataset is unlabeled, we went about labeling a smaller subset of the tweets ourselves by creating a `Label` column and assigning 0 for tweets that are not Islamophobic and 1 for tweets that are Islamophobic. There are 180 tweets total that are labeled with a class balance of 50-50. We will use this subset of tweets for training and testing our classifier models.\n",
    "\n",
    "Next, we will take a number of steps to clean the dataset:\n",
    "1. Removing the following columns as they do not provide information necessary for this investigation: `Quick Notes`, `Custom Reports`, `Workflow`, `Legislative Tracker`.\n",
    "2. Remove data entries with tweets that are null values or only include hyperlinks or photos.\n",
    "3. Replace hyperlinks included in tweets with standard tokens to reduce noise.\n",
    "4. Fixing spelling errors contained in the `Post Text` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8d1ffa45-e60c-4436-87da-69ead2121e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed14b746-d1f2-4f4b-a783-e60cf8c87b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>X Accounts</th>\n",
       "      <th>Post Link</th>\n",
       "      <th>Post Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Bookmarks</th>\n",
       "      <th>Views</th>\n",
       "      <th>Quick Notes</th>\n",
       "      <th>Custom Reports</th>\n",
       "      <th>Workflow</th>\n",
       "      <th>Legislative Tracker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/8/2026</td>\n",
       "      <td>Nadia Rahman Èß±ÈõØ</td>\n",
       "      <td>https://x.com/nadiarahmansf/status/20091324931...</td>\n",
       "      <td>The defining moment of the first congressional...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1062.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>6318.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>355035.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/8/2026</td>\n",
       "      <td>John Guandolo</td>\n",
       "      <td>https://x.com/JGuandolo54271/status/2009080087...</td>\n",
       "      <td>@WallStreetApes Diyanet Center of America\\nISN...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/7/2026</td>\n",
       "      <td>Pamela Hensleyüá∫üá∏</td>\n",
       "      <td>https://x.com/i/status/2008756328928538637</td>\n",
       "      <td>There is an Iranian-run daycare in Los Angeles...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5571.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>34300.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>256927.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date        X Accounts  \\\n",
       "0  1/8/2026   Nadia Rahman Èß±ÈõØ   \n",
       "1  1/8/2026     John Guandolo   \n",
       "2  1/7/2026  Pamela Hensleyüá∫üá∏   \n",
       "\n",
       "                                           Post Link  \\\n",
       "0  https://x.com/nadiarahmansf/status/20091324931...   \n",
       "1  https://x.com/JGuandolo54271/status/2009080087...   \n",
       "2         https://x.com/i/status/2008756328928538637   \n",
       "\n",
       "                                           Post Text  Label  Retweets  \\\n",
       "0  The defining moment of the first congressional...    NaN    1062.0   \n",
       "1  @WallStreetApes Diyanet Center of America\\nISN...    NaN       3.0   \n",
       "2  There is an Iranian-run daycare in Los Angeles...    NaN    5571.0   \n",
       "\n",
       "   Comments    Likes  Bookmarks     Views Quick Notes Custom Reports Workflow  \\\n",
       "0     155.0   6318.0      532.0  355035.0         NaN            NaN      NaN   \n",
       "1       0.0     14.0        1.0     426.0         NaN            NaN      NaN   \n",
       "2     328.0  34300.0      324.0  256927.0         NaN            NaN      NaN   \n",
       "\n",
       "  Legislative Tracker  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 NaN  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading in our data\n",
    "\n",
    "df = pd.read_csv('data/tweets_labeled.csv', header=0)\n",
    "\n",
    "# making sure dataset loaded in properly\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "152a5cbe-af4f-4e35-98a5-788a59c43244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1619, 14)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5c89cb73-3362-4cb1-93f4-d1341eb2ecf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'X Accounts', 'Post Link', 'Post Text', 'Label', 'Retweets',\n",
       "       'Comments', 'Likes', 'Bookmarks', 'Views', 'Quick Notes',\n",
       "       'Custom Reports', 'Workflow', 'Legislative Tracker'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0602c0ed-8e7f-4012-8482-ef8846cfbad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>X Accounts</th>\n",
       "      <th>Post Link</th>\n",
       "      <th>Post Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Bookmarks</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/8/2026</td>\n",
       "      <td>Nadia Rahman Èß±ÈõØ</td>\n",
       "      <td>https://x.com/nadiarahmansf/status/20091324931...</td>\n",
       "      <td>The defining moment of the first congressional...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1062.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>6318.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>355035.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/8/2026</td>\n",
       "      <td>John Guandolo</td>\n",
       "      <td>https://x.com/JGuandolo54271/status/2009080087...</td>\n",
       "      <td>@WallStreetApes Diyanet Center of America\\nISN...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/7/2026</td>\n",
       "      <td>Pamela Hensleyüá∫üá∏</td>\n",
       "      <td>https://x.com/i/status/2008756328928538637</td>\n",
       "      <td>There is an Iranian-run daycare in Los Angeles...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5571.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>34300.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>256927.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date        X Accounts  \\\n",
       "0  1/8/2026   Nadia Rahman Èß±ÈõØ   \n",
       "1  1/8/2026     John Guandolo   \n",
       "2  1/7/2026  Pamela Hensleyüá∫üá∏   \n",
       "\n",
       "                                           Post Link  \\\n",
       "0  https://x.com/nadiarahmansf/status/20091324931...   \n",
       "1  https://x.com/JGuandolo54271/status/2009080087...   \n",
       "2         https://x.com/i/status/2008756328928538637   \n",
       "\n",
       "                                           Post Text  Label  Retweets  \\\n",
       "0  The defining moment of the first congressional...    NaN    1062.0   \n",
       "1  @WallStreetApes Diyanet Center of America\\nISN...    NaN       3.0   \n",
       "2  There is an Iranian-run daycare in Los Angeles...    NaN    5571.0   \n",
       "\n",
       "   Comments    Likes  Bookmarks     Views  \n",
       "0     155.0   6318.0      532.0  355035.0  \n",
       "1       0.0     14.0        1.0     426.0  \n",
       "2     328.0  34300.0      324.0  256927.0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing unnecessary columns\n",
    "\n",
    "df_clean = df.drop(columns=['Quick Notes', 'Custom Reports', 'Workflow', 'Legislative Tracker'])\n",
    "\n",
    "# making sure the columns were removed correctly\n",
    "\n",
    "df_clean.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fcf0e1-fd77-4d45-81f2-a3e2678fa9fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "38d24d73-0a3e-49b9-b139-4c884f2da341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking to see if there are any null entries under the `Post Text` column\n",
    "\n",
    "df_clean['Post Text'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "985ee4db-0556-40f1-8f16-ecb67a5e11f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>X Accounts</th>\n",
       "      <th>Post Link</th>\n",
       "      <th>Post Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Bookmarks</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>7/16/2025</td>\n",
       "      <td>W H Y T E_R Y K</td>\n",
       "      <td>https://twitter.com/RealWhyteRyk/status/194551...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>5/23/2025</td>\n",
       "      <td>üîªüáÆüá∂üáµüá∏üá±üáßüáæüá™üá∞üáµüáÆüá∑üîª</td>\n",
       "      <td>https://x.com/notbasrairaqi2/status/1925890468...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>5/22/2025</td>\n",
       "      <td>‚ò≠ ü™Çüê∂ KarlüîªBarx üê∂ü™Ç‚ò≠</td>\n",
       "      <td>https://x.com/Karl_Barxxx/status/1925584865715...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6429.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>5/22/2025</td>\n",
       "      <td>julia üîªü™Ç</td>\n",
       "      <td>https://x.com/k1myojong/status/192560532264050...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5485.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>5/22/2025</td>\n",
       "      <td>descriptive display name that is way too long and</td>\n",
       "      <td>https://x.com/mrgracemugabe/status/19255601712...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>264200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>5/20/2025</td>\n",
       "      <td>Ihcen üîª</td>\n",
       "      <td>https://x.com/ihcentoo/status/1924981885576303047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>2/16/2025</td>\n",
       "      <td>SaltyGoy2083</td>\n",
       "      <td>https://x.com/goy208395235/status/189128417012...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date                                         X Accounts  \\\n",
       "1471  7/16/2025                                    W H Y T E_R Y K   \n",
       "1479  5/23/2025                                     üîªüáÆüá∂üáµüá∏üá±üáßüáæüá™üá∞üáµüáÆüá∑üîª   \n",
       "1501  5/22/2025                                 ‚ò≠ ü™Çüê∂ KarlüîªBarx üê∂ü™Ç‚ò≠   \n",
       "1502  5/22/2025                                           julia üîªü™Ç   \n",
       "1504  5/22/2025  descriptive display name that is way too long and   \n",
       "1505  5/20/2025                                            Ihcen üîª   \n",
       "1610  2/16/2025                                       SaltyGoy2083   \n",
       "\n",
       "                                              Post Link Post Text  Label  \\\n",
       "1471  https://twitter.com/RealWhyteRyk/status/194551...       NaN    NaN   \n",
       "1479  https://x.com/notbasrairaqi2/status/1925890468...       NaN    NaN   \n",
       "1501  https://x.com/Karl_Barxxx/status/1925584865715...       NaN    NaN   \n",
       "1502  https://x.com/k1myojong/status/192560532264050...       NaN    NaN   \n",
       "1504  https://x.com/mrgracemugabe/status/19255601712...       NaN    NaN   \n",
       "1505  https://x.com/ihcentoo/status/1924981885576303047       NaN    NaN   \n",
       "1610  https://x.com/goy208395235/status/189128417012...       NaN    NaN   \n",
       "\n",
       "      Retweets  Comments    Likes  Bookmarks     Views  \n",
       "1471       NaN       NaN      NaN        NaN       NaN  \n",
       "1479       1.0       0.0      0.0        0.0      35.0  \n",
       "1501      26.0       1.0    276.0        5.0    6429.0  \n",
       "1502      67.0       4.0    329.0       14.0    5485.0  \n",
       "1504    1300.0      40.0  17000.0      522.0  264200.0  \n",
       "1505      42.0       0.0    254.0       20.0    4473.0  \n",
       "1610       NaN       NaN      NaN        NaN       NaN  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seeing which rows have null values\n",
    "\n",
    "df_clean[df_clean[\"Post Text\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "08fbac9b-0005-4f4d-9d17-927c865edd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping rows with null values in `Post Text`\n",
    "\n",
    "df_clean = df_clean.dropna(subset=['Post Text']).copy()\n",
    "\n",
    "# making sure it worked\n",
    "\n",
    "df_clean['Post Text'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f7302a-a9b8-43b9-9244-9428088e9441",
   "metadata": {},
   "source": [
    "### `clean_tweet()` Text Preprocessing Function\n",
    "Now that we've removed null values under `Post Text` and unnecessary columns, next we need to clean the text we will be analyzing by handling hyperlinks and spelling errors.\n",
    "\n",
    "We will do this by creating a a **function for text preprocessing** called `clean_tweet`() to perform the following:\n",
    "- Lowercase text.\n",
    "- Replace URLs with \"URL\".\n",
    "- Replace @mentions with \"USER\".\n",
    "- Normalize quotes.\n",
    "- Removes extra whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a2b00b7a-4ce8-4990-b837-f998d8a4d010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(text):\n",
    "    \n",
    "    # lowercase everything so words are treated the same regardless of capitalization\n",
    "    text = text.lower()\n",
    "    \n",
    "    # standardizing quotation marks and apostrophes so text is consistent\n",
    "    text = text.replace(\"‚Äú\", '\"').replace(\"‚Äù\", '\"')\n",
    "    text = text.replace(\"‚Äô\", \"'\").replace(\"‚Äò\", \"'\")\n",
    "    \n",
    "    # replacing hyperlinks with the token \"URL\"\n",
    "    text = re.sub(r\"http\\S+|www\\.\\S+\", \" URL \", text)\n",
    "    \n",
    "    # replacing usernames with the token \"USER\"\n",
    "    text = re.sub(r\"@\\w+\", \" USER \", text)\n",
    "    \n",
    "    # removing hashtags \n",
    "    text = text.replace(\"#\", \"\")\n",
    "    \n",
    "    # replacing multiple spaces/white space with a single space and stripping extra spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4c01dadd-89df-413e-866a-6b2765f7da54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the function to every row in the `Post Text` column\\\n",
    "# and creaating a a new column that we will use for modeling\n",
    "df_clean['Clean Text'] = df_clean['Post Text'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9763e11a-8b87-47bc-974a-abaa63882b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>X Accounts</th>\n",
       "      <th>Post Link</th>\n",
       "      <th>Post Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Bookmarks</th>\n",
       "      <th>Views</th>\n",
       "      <th>Clean Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/8/2026</td>\n",
       "      <td>Nadia Rahman Èß±ÈõØ</td>\n",
       "      <td>https://x.com/nadiarahmansf/status/20091324931...</td>\n",
       "      <td>The defining moment of the first congressional...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1062.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>6318.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>355035.0</td>\n",
       "      <td>the defining moment of the first congressional...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/8/2026</td>\n",
       "      <td>John Guandolo</td>\n",
       "      <td>https://x.com/JGuandolo54271/status/2009080087...</td>\n",
       "      <td>@WallStreetApes Diyanet Center of America\\nISN...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>USER diyanet center of america isna uscmo icna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/7/2026</td>\n",
       "      <td>Pamela Hensleyüá∫üá∏</td>\n",
       "      <td>https://x.com/i/status/2008756328928538637</td>\n",
       "      <td>There is an Iranian-run daycare in Los Angeles...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5571.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>34300.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>256927.0</td>\n",
       "      <td>there is an iranian-run daycare in los angeles...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date        X Accounts  \\\n",
       "0  1/8/2026   Nadia Rahman Èß±ÈõØ   \n",
       "1  1/8/2026     John Guandolo   \n",
       "2  1/7/2026  Pamela Hensleyüá∫üá∏   \n",
       "\n",
       "                                           Post Link  \\\n",
       "0  https://x.com/nadiarahmansf/status/20091324931...   \n",
       "1  https://x.com/JGuandolo54271/status/2009080087...   \n",
       "2         https://x.com/i/status/2008756328928538637   \n",
       "\n",
       "                                           Post Text  Label  Retweets  \\\n",
       "0  The defining moment of the first congressional...    NaN    1062.0   \n",
       "1  @WallStreetApes Diyanet Center of America\\nISN...    NaN       3.0   \n",
       "2  There is an Iranian-run daycare in Los Angeles...    NaN    5571.0   \n",
       "\n",
       "   Comments    Likes  Bookmarks     Views  \\\n",
       "0     155.0   6318.0      532.0  355035.0   \n",
       "1       0.0     14.0        1.0     426.0   \n",
       "2     328.0  34300.0      324.0  256927.0   \n",
       "\n",
       "                                          Clean Text  \n",
       "0  the defining moment of the first congressional...  \n",
       "1  USER diyanet center of america isna uscmo icna...  \n",
       "2  there is an iranian-run daycare in los angeles...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making sure the function worked properly\n",
    "\n",
    "df_clean.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5dcfad-a071-407e-a3b3-5edf03071440",
   "metadata": {},
   "source": [
    "#### With the whole data set cleaned up, we can start preparing ourselves for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2916ac-25a4-4763-a743-08af08f86eff",
   "metadata": {},
   "source": [
    "### Extracting Labeled Data\n",
    "\n",
    "As discussed above, only a smaller subset of the rows within the larger data set contain labels that we manually entered under the new column, `Label`, with a 0 indicating the tweet is not Islamophobic and a 1 indicating the tweet is Islamophobic.\n",
    "\n",
    "We now need to extract those labeled rows so that we can use them to train our classifier and perform our modeling. We will refer to this as `df_labeled`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "de64e7fc-35c6-425c-8ce8-aa74d09fd07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 11)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a new dataframe that contains only the labeled data from df_clean\n",
    "\n",
    "df_labeled = df_clean[df_clean[\"Label\"].notna()].copy()\n",
    "\n",
    "# making sure it worked\n",
    "\n",
    "df_labeled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "71bc9748-e724-4cd5-b9f8-24a2685154ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    90\n",
       "1    90\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turning label values into integers\n",
    "df_labeled[\"Label\"] = df_labeled[\"Label\"].astype(int)\n",
    "\n",
    "df_labeled[\"Label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d96758c-e124-4035-9209-728843e2dcde",
   "metadata": {},
   "source": [
    "### Splitting the Data\n",
    "\n",
    "Next, we will split our data into Training and Testing sets to use in our pipelines later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7fceb6cf-7679-4e57-a738-5fe4a711144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating our X (features) and y (target) \n",
    "\n",
    "X = df_labeled[\"Clean Text\"]  \n",
    "y = df_labeled[\"Label\"]        \n",
    "\n",
    "# creating the Train-Test Splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y # making sure the sets have the same class balance\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db08a60-6f5c-4c77-8827-8506188e34fb",
   "metadata": {},
   "source": [
    "# III. Data Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8711fda-3d86-4ef2-b24d-b425fab040b3",
   "metadata": {},
   "source": [
    "Now that our data is preprocessed and our Training and Testing sets are ready, we'll start constructing our modeling pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aa4c35-c532-43d7-b35e-a305fed863f6",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b77d83-c486-4498-bccf-78844f2c5b17",
   "metadata": {},
   "source": [
    "As discussed earlier, we will be creating two model pipelines:\n",
    "1. `Logistic Regression` with TF-IDF Vectorizer\n",
    "2. `LinearSVM` with TF-IDF Vectorizer\n",
    "\n",
    "As a reminder, we are aiming to maximize **Precision** as our primary metric (and will consider the Recall score as supplementary), so we will tune the pipeline's parameters accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9a922485-5719-4c04-94c6-79c18f7c5354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the Logistic Regression + TF-IDF pipeline\n",
    "logreg_pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        ngram_range=(1,2),      # include bigrams\n",
    "        min_df=2,               # exclude words that only appear once\n",
    "        max_df=0.95             # exclude words that are too common\n",
    "    )), \n",
    "    (\"clf\", LogisticRegression(\n",
    "        max_iter=2000, \n",
    "        class_weight=\"balanced\"\n",
    "    )) \n",
    "])\n",
    "\n",
    "# creating the Linear SVM + TF-IDF pipeline\n",
    "svm_pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        ngram_range=(1,2), \n",
    "        min_df=2, \n",
    "        max_df=0.95\n",
    "    )),\n",
    "    (\"clf\", LinearSVC(\n",
    "        class_weight=\"balanced\"\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "38784438-da9c-4ed2-9b66-aeb9dad82013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogReg\n",
      "Precision: 1.000\n",
      "Recall:    0.833\n",
      "\n",
      "LinearSVM\n",
      "Precision: 1.000\n",
      "Recall:    0.889\n"
     ]
    }
   ],
   "source": [
    "# creating for loop to fit and run the models and provide metric scores\n",
    "models = {\n",
    "    \"LogReg\": logreg_pipe,\n",
    "    \"LinearSVM\": svm_pipe\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    precision = precision_score(y_test, preds)\n",
    "    recall = recall_score(y_test, preds)\n",
    "\n",
    "    print(f\"\\n{name}\")\n",
    "    print(f\"Precision: {precision:.3f}\")\n",
    "    print(f\"Recall:    {recall:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9aa19d-97e8-423e-99b0-7f44f735a504",
   "metadata": {},
   "source": [
    "These are **excellent** scores, with zero False Positives and 2-3 False Negatives.\n",
    "\n",
    "It tells us that both models successfully kept all False Positives out of the Islamophobic tweets bucket, and each only missed a few Islamophobic tweets that it mistakenly marked as not Islamophobic.\n",
    "\n",
    "However, these scores may be too good to be true, and could be due to our relatively small collection of labeled tweets. \n",
    "\n",
    "To increase our confidence in these models, we will add a **cross-validation** component to the pipelines and run them again, so we can be more sure of the models' competence when applying them to the wider dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80997554-efcc-4ad2-a389-a2654d808142",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c8709b-3987-43d2-b8f6-0240febd8b45",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12ea7312-2432-487c-aaff-846fec41b331",
   "metadata": {},
   "source": [
    "# IV. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f4b009-30b4-47a7-b7ee-ed8b9981eebc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2436db86-bc61-4858-8cdd-ba21c92dbfd3",
   "metadata": {},
   "source": [
    "## Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1349df-046a-4c4b-b531-3d6fa2240d94",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38d84cd8-fe33-4452-a81b-f7a31cc9927e",
   "metadata": {},
   "source": [
    "## Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e860e9-c39c-48dc-9a57-a387d5d27b3a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c80c11c1-0056-452c-bd70-ecde66b57769",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb772f7-1a7e-4f8f-a0ae-0cb24a71c6b5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
