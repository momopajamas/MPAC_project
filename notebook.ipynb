{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c626feae-933c-4be9-a3a2-cc38602e357d",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "With the upsurge in Islamophobia rhetoric in recent months that is starkly reminiscient of a post-9/11 climate in the US and the West, the Muslim Public Affairs Committee (MPAC) has tasked the Center for Security, Technology, and Policy (CSTP) with locating trends within this discourse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d023be5b-5ee0-4326-a4f6-55f6d150861c",
   "metadata": {},
   "source": [
    " ## Problem Understanding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634fd33d-32ae-4494-8b16-07f2cfd37b01",
   "metadata": {},
   "source": [
    "The goal of this project is to identify dominant themes and patterns underpinning Islamophobic rhetoric in order to better inform research and policy recommendations. Specifically, this project focuses on extracting actionable insights by identifying recurring language patterns, narrative frames, and potential changes in discourse that can support effective advocacy, monitoring, and community safety responses. To accomplish this, we analyze a dataset of public posts from X (formerly Twitter) from a variety of users. \n",
    "\n",
    "Because large-scale manual review of social media content is not feasible, this project also includes a lightweight machine learning component designed to support scalable detection. First, we build a baseline NLP classifier that can distinguish between Islamophobic and non-Islamophobic tweets. Then, using the tweets identified as Islamophobic, we apply thematic analysis (e.g., clustering/topic discovery) to surface the most common narratives and rhetorical patterns present in the dataset. This combined approach supports both detection (what content should be flagged for review) and understanding (what narratives are driving the discourse).\n",
    "\n",
    "### Project Scope\n",
    "- The dataset consists of 1,619 tweets collected from X.\n",
    "- Because the dataset does not include pre-existing labels, the project creates a small, high-confidence manually labeled subset to train and evaluate a baseline classifier.\n",
    "- The modeling approach prioritizes interpretability and speed, using traditional NLP features (e.g., TF-IDF) and linear models rather than computationally expensive deep learning approaches.\n",
    "- After classification, the subset of Islamophobic tweets is used to perform theme discovery, producing interpretable clusters/topics supported by representative examples and key terms.\n",
    "- Due to the sensitive nature of the domain and the risk of harm from misclassification, the classifier is framed as a decision-support tool rather than an automatic enforcement system.\n",
    "\n",
    "### Success Criteria\n",
    "Success for this project can be measured by answering three questions:\n",
    "\n",
    "**1. Is the classifier functional and reliable enough to support triage?**\n",
    "- Performance will be evaluated using a confusion matrix and metrics such as precision, recall, and F1-score, with a particular emphasis on precision to reduce harmful false positives.\n",
    "\n",
    "**2. Did we learn something real, clear, and repeatable about the discourse?**\n",
    "- Thematic outputs should produce coherent categories of Islamophobic rhetoric (e.g., dehumanization, collective blame, exclusionary policy narratives, conspiracy framing) supported by representative tweets and distinguishing keywords.\n",
    "\n",
    "**4. Can the insights inform real decisions?**\n",
    "- Findings should translate into concrete, stakeholder-relevant outputs such as narrative summaries, “watchlist” language patterns, and recommendations that can inform policy memos, rapid response, or platform monitoring strategies.\n",
    "\n",
    "### Limitations & Ethics\n",
    "Islamophobia detection is highly context-dependent and can involve sarcasm, coded language, and quotation, making the task difficult even for human reviewers. Because the dataset does not include ground-truth labels, this project relies on a small manually labeled subset, which introduces subjectivity and may not reflect all language patterns in the full dataset. The classifier may also produce false positives when tweets mention Islam or Muslims in neutral or advocacy contexts. For these reasons, the model should be treated as a decision-support tool for triage rather than an automatic enforcement mechanism. A production-ready version would require larger labeled data, multiple annotators, and additional bias/fairness evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4def5b5-97f4-4c18-a13b-81765b727851",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f98998-ef5b-483e-af8c-0f43ad6d262b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42f5bca7-eb93-4533-a89c-fb25d4766460",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1facf27c-039c-4d03-94a6-31053a91bba3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4db08a60-6f5c-4c77-8827-8506188e34fb",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8711fda-3d86-4ef2-b24d-b425fab040b3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10aa4c35-c532-43d7-b35e-a305fed863f6",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80997554-efcc-4ad2-a389-a2654d808142",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12ea7312-2432-487c-aaff-846fec41b331",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f4b009-30b4-47a7-b7ee-ed8b9981eebc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2436db86-bc61-4858-8cdd-ba21c92dbfd3",
   "metadata": {},
   "source": [
    "## Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1349df-046a-4c4b-b531-3d6fa2240d94",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38d84cd8-fe33-4452-a81b-f7a31cc9927e",
   "metadata": {},
   "source": [
    "## Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e860e9-c39c-48dc-9a57-a387d5d27b3a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c80c11c1-0056-452c-bd70-ecde66b57769",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb772f7-1a7e-4f8f-a0ae-0cb24a71c6b5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
