{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c626feae-933c-4be9-a3a2-cc38602e357d",
   "metadata": {},
   "source": [
    "# I. Introduction\n",
    "\n",
    "With the upsurge in Islamophobia rhetoric in recent months that is starkly reminiscient of a post-9/11 climate in the US and the West, the Muslim Public Affairs Committee (MPAC) has tasked the Center for Security, Technology, and Policy (CSTP) with locating trends within this discourse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d023be5b-5ee0-4326-a4f6-55f6d150861c",
   "metadata": {},
   "source": [
    " ## Problem Understanding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634fd33d-32ae-4494-8b16-07f2cfd37b01",
   "metadata": {},
   "source": [
    "The goal of this project is to identify dominant themes and patterns underpinning Islamophobic rhetoric in order to better inform research and policy recommendations. Specifically, this project focuses on extracting actionable insights by identifying recurring language patterns, narrative frames, and potential changes in discourse that can support effective advocacy, monitoring, and community safety responses. To accomplish this, we analyze a dataset of public posts from X (formerly Twitter) from a variety of users. \n",
    "\n",
    "Because large-scale manual review of social media content is not feasible, this project also includes a lightweight machine learning component designed to support scalable detection. First, we build a baseline NLP classifier that can distinguish between Islamophobic and non-Islamophobic tweets. Then, using the tweets identified as Islamophobic, we apply thematic analysis (e.g., clustering/topic discovery) to surface the most common narratives and rhetorical patterns present in the dataset. This combined approach supports both detection (what content should be flagged for review) and understanding (what narratives are driving the discourse).\n",
    "\n",
    "#### Defining Islamophobia\n",
    "\n",
    "Islamophobia as a concept can encompass a variety of rhetoric, depending on the definition one uses. For the purposes of this project, we will use the definition of Islamophobia used by the [Bridge Initiative at Georgetown University](https://bridge.georgetown.edu/about-us/what-is-islamophobia/), which posits that \"*Islamophobia is an extreme fear of and hostility toward Islam and Muslims which often leads to hate speech, hate crimes, as well as social and political discrimination.*\"\n",
    "\n",
    "We use this definition in order to limit the scope of the investigation to rhetoric that echos fears and hatred of Islam and Muslims specifically. In order to maintain focus, tweets that are critical or antagonistic to Muslim-majority states, for example, would only be considered Islamophobic if the rhetoric used directly or implicitly attacks Islam as a religion or Muslims as a people.\n",
    "\n",
    "### Project Scope\n",
    "- The dataset consists of 1,619 tweets collected from X.\n",
    "- The project creates a small, high-confidence manually labeled subset to train and evaluate a baseline classifier.\n",
    "- The dataset is unlabeled. We will create a small set of 200 tweets, half labeled 0 for not Islamophobic, and the other half labeled 1 for Islamophobic.\n",
    "- The modeling approach prioritizes interpretability and speed, using traditional NLP features (e.g., TF-IDF) and linear models rather than computationally expensive deep learning approaches.\n",
    "- After classification, the subset of Islamophobic tweets is used to perform theme discovery, producing interpretable clusters/topics supported by representative examples and key terms.\n",
    "- Due to the sensitive nature of the domain and the risk of harm from misclassification, the classifier is framed as a decision-support tool rather than an automatic enforcement system.\n",
    "\n",
    "### Success Criteria\n",
    "Success for this project can be measured by answering three questions:\n",
    "\n",
    "**1. Is the classifier functional and reliable enough to support triage?**\n",
    "- Performance will be evaluated using a confusion matrix and metrics such as precision, recall, and F1-score, with a particular emphasis on precision to reduce harmful false positives.\n",
    "\n",
    "**2. Did we learn something real, clear, and repeatable about the discourse?**\n",
    "- Thematic outputs should produce coherent categories of Islamophobic rhetoric (e.g., dehumanization, collective blame, exclusionary policy narratives, conspiracy framing) supported by representative tweets and distinguishing keywords.\n",
    "\n",
    "**3. Can the insights inform real decisions?**\n",
    "- Findings should translate into concrete, stakeholder-relevant outputs such as narrative summaries, language patterns, and recommendations that can inform policy memos, rapid response, or platform monitoring strategies.\n",
    "\n",
    "### Limitations & Ethics\n",
    "Islamophobia detection is highly context-dependent and can involve sarcasm, coded language, and quotation, making the task difficult even for human reviewers. Because the dataset does not include ground-truth labels, this project relies on a small manually labeled subset, which introduces subjectivity and may not reflect all language patterns in the full dataset. The classifier may also produce false positives when tweets mention Islam or Muslims in neutral or advocacy contexts. For these reasons, the model should be treated as a decision-support tool for triage rather than an automatic enforcement mechanism. A production-ready version would require larger labeled data, multiple annotators, and additional bias/fairness evaluation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4def5b5-97f4-4c18-a13b-81765b727851",
   "metadata": {},
   "source": [
    "# II. Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f98998-ef5b-483e-af8c-0f43ad6d262b",
   "metadata": {},
   "source": [
    "This dataset contains 1,619 public posts from X (formerly Twitter). Each row represents a single post and includes the post text, metadata about the author account, and engagement metrics. The data is intended to support analysis of Islamophobic discourse by enabling both language-based analysis (what is being said) and impact-based analysis (how widely it spreads).\n",
    "\n",
    "### Features\n",
    "- `Date`: Timestamp associated with the post. This allows trend analysis over time (e.g., spikes in activity or engagement).\n",
    "- `X Accounts`: The username or account identifier that published the post. This can be used to assess repetition, concentration of posting behavior, or high-volume accounts.\n",
    "- `Post Link`: Direct URL to the post for auditing and transparency.\n",
    "- `Post Text`: The main content of the tweet. This is the primary input feature for NLP tasks such as classification and theme discovery.\n",
    "- `Retweets` / `Comments` / `Likes` / `Bookmarks` / `Views`: Engagement metrics that approximate reach and amplification. Views represent the broadest measure of exposure, while retweets and bookmarks may indicate stronger forms of engagement.\n",
    "- `Custom Reports`: While this column is mostly empty, around 90 or so entries are marked as 'Islamophobic.' We will consider these entries as high-confidence labels and use them as a starting point to train our classifier.\n",
    "- `Quick Notes`/ `Legistlative Tracker`/ `Workflow`:  These are almost entirly empty, and the few entries contain nothing of value for our purposes, and we will need to cut these to clean our dataset.\n",
    "\n",
    "This dataset supports three core types of analysis:\n",
    "\n",
    "**1. Classification**: Using the post text to train a classifier that can triage harmful content.\n",
    "\n",
    "**2. Topic Modeling**: Identifying recurring narratives and language patterns within Islamophobic tweets (e.g., stereotypes, collective blame, exclusionary rhetoric).\n",
    "\n",
    "**3. Impact Analysis**: Using engagement metrics, especially views and retweets, to understand which narratives are most amplified and hold higher degrees of salience, and therefore may pose greater public influence or harm.\n",
    "\n",
    "### Quality Considerations\n",
    "\n",
    "Several quality issues are present in this dataset:\n",
    "\n",
    "- Missing or inconsistent labels: The dataset does not appear to have complete, standardized annotation fields. Some rows may contain partial labeling information, while most remain unlabeled.\n",
    "- Context loss: Tweets are short and often depend on context (threads, quotes, sarcasm, or external links or links to other tweets). This creates ambiguity when interpreting intent.\n",
    "- Noise in text: Tweet text may include URLs, mentions (@user), hashtags, emojis, or formatting artifacts that require preprocessing.\n",
    "- Engagement bias: Views and engagement are influenced by account size, virality dynamics, and platform algorithms, not only the content itself, so they should be interpreted as approximate impact signals rather than direct measures of harm.\n",
    "- Sampling bias: The dataset may not represent the full spectrum of Twitter discourse. It may be shaped by how the tweets were collected (search terms, accounts, timeframe).\n",
    "\n",
    "Additionally, the scope of this project and the nature of this dataset combined to create a number of limitations:\n",
    "- Our focus on identifying Islamophobia in particular leads us to exclude rhetoric containing other forms of hate and extremism, such as anti-Hindu or antisemitic rhetoric, which can often emanate from the same source or utilize overlapping forms of rhetoric.\n",
    "- Some tweets are antagonostic towards ethnicities or countries, and do not constitute Islamophobia in the strict sense we outlined above.\n",
    "- A large portion of the Islamophobic tweets present address particular social or political situations, such as controversies over mosques in Texas or the alleged fraud allegations of Somalis in Minnesota, which could potentially limit the extent of generalizability of identified themes.\n",
    "- The vast majority of the tweets deal with the the US context specifically, which could limit the transnational dimensions of Islamophobia.\n",
    "\n",
    "### Assumptions\n",
    "\n",
    "To keep the project feasible in a short timeline, the project assumes the following:\n",
    "\n",
    "- The post text contains enough signal to differentiate Islamophobic from non-Islamophobic content at a baseline level.\n",
    "- A small high-confidence labeled subset can provide enough ground truth to evaluate a lightweight baseline model.\n",
    "- The classified tweets can be clustered to extrect recurring themes and trends present within online Islamophobic discourse that can be generalized.\n",
    "- Engagement metrics such as Likes and Retweets can help us better understand which narratives and themes are echoed the most and have more salience for the public.\n",
    "\n",
    "### Model Selection\n",
    "\n",
    "For efficiency, we will deploy two models and assess how they perform on training and test data Both models will incorporate **Term Frequency-Inverse Document Frequency (TF-IDF)**, which will be useful in determining the relative significance of terms used across the content under `Post Text` by weighing the frequency of the appearance of those terms within a tweet against their relative rarity across all tweets in the dataset.\n",
    "\n",
    "1. `Logistic Regression`: This will be our baseline model as it is strong in text classification and relatively quick to train. The probabilities given by this model will potentially be useful for threshold tuning, and can provide us with the top words driving predictions.\n",
    "2. `LinearSVM`: This model excels at high-dimensional sparse text, and is likewise quick to train and robust.\n",
    "\n",
    "### Metrics\n",
    "\n",
    "For our purposes of narrative and trend analysis, **False Positives are more harmful than False Negatives**. This is because, while it would be unfortunate to mistakenly classify tweets as not Islamophobic when they actually are, the impact of this misclassification on our trend analysis would be minimized by the fact that, according to our assumptions, there are trends and recurring themes across these tweets. However, it would be far more detrimental to our analysis if our 'bucket' of Islamophobic tweets were polluted by tweets that are not Islamophobic, as this would distort the themes we extract and the conclusions we draw from them.\n",
    "\n",
    "Therefore, we will be using **Precision** as our primary metric of success, as this evaluates our ability to **keep False Positives out** and generate a high-confidence subset for analysis. In other words, it measures how 'pure' our Islamophobic bucket of tweets is, ensuring that the themes we extract are more cohesive and accurate.\n",
    "\n",
    "### Cross-Validation\n",
    "\n",
    "Since we are working with a relatiely limited set of labeled data of only 180 entries, we will need to ensure that our models are functioning competently and not by mere luck. We can do this by relying on cross-validation, which will run several data splits instead of just one, and will use `Stratified K-Means` to conduct those splits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f5bca7-eb93-4533-a89c-fb25d4766460",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78df8caf-6e01-4df3-aeb9-3dc43efa3298",
   "metadata": {},
   "source": [
    "Several steps need to be taken before we are able to begin modeling and analyzing the data.\n",
    "\n",
    "First, since the dataset is unlabeled, we went about labeling a smaller subset of the tweets ourselves by creating a `Label` column and assigning 0 for tweets that are not Islamophobic and 1 for tweets that are Islamophobic. There are 180 tweets total that are labeled with a class balance of 50-50. We will use this subset of tweets for training and testing our classifier models.\n",
    "\n",
    "Next, we will take a number of steps to clean the dataset:\n",
    "1. Removing the following columns as they do not provide information necessary for this investigation: `Quick Notes`, `Custom Reports`, `Workflow`, `Legislative Tracker`.\n",
    "2. Remove data entries with tweets that are null values or only include hyperlinks or photos.\n",
    "3. Replace hyperlinks included in tweets with standard tokens to reduce noise.\n",
    "4. Fixing spelling errors contained in the `Post Text` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8d1ffa45-e60c-4436-87da-69ead2121e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ed14b746-d1f2-4f4b-a783-e60cf8c87b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>X Accounts</th>\n",
       "      <th>Post Link</th>\n",
       "      <th>Post Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Bookmarks</th>\n",
       "      <th>Views</th>\n",
       "      <th>Quick Notes</th>\n",
       "      <th>Custom Reports</th>\n",
       "      <th>Workflow</th>\n",
       "      <th>Legislative Tracker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/8/2026</td>\n",
       "      <td>Nadia Rahman Èß±ÈõØ</td>\n",
       "      <td>https://x.com/nadiarahmansf/status/20091324931...</td>\n",
       "      <td>The defining moment of the first congressional...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1062.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>6318.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>355035.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/8/2026</td>\n",
       "      <td>John Guandolo</td>\n",
       "      <td>https://x.com/JGuandolo54271/status/2009080087...</td>\n",
       "      <td>@WallStreetApes Diyanet Center of America\\nISN...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/7/2026</td>\n",
       "      <td>Pamela Hensleyüá∫üá∏</td>\n",
       "      <td>https://x.com/i/status/2008756328928538637</td>\n",
       "      <td>There is an Iranian-run daycare in Los Angeles...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5571.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>34300.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>256927.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date        X Accounts  \\\n",
       "0  1/8/2026   Nadia Rahman Èß±ÈõØ   \n",
       "1  1/8/2026     John Guandolo   \n",
       "2  1/7/2026  Pamela Hensleyüá∫üá∏   \n",
       "\n",
       "                                           Post Link  \\\n",
       "0  https://x.com/nadiarahmansf/status/20091324931...   \n",
       "1  https://x.com/JGuandolo54271/status/2009080087...   \n",
       "2         https://x.com/i/status/2008756328928538637   \n",
       "\n",
       "                                           Post Text  Label  Retweets  \\\n",
       "0  The defining moment of the first congressional...    NaN    1062.0   \n",
       "1  @WallStreetApes Diyanet Center of America\\nISN...    NaN       3.0   \n",
       "2  There is an Iranian-run daycare in Los Angeles...    NaN    5571.0   \n",
       "\n",
       "   Comments    Likes  Bookmarks     Views Quick Notes Custom Reports Workflow  \\\n",
       "0     155.0   6318.0      532.0  355035.0         NaN            NaN      NaN   \n",
       "1       0.0     14.0        1.0     426.0         NaN            NaN      NaN   \n",
       "2     328.0  34300.0      324.0  256927.0         NaN            NaN      NaN   \n",
       "\n",
       "  Legislative Tracker  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 NaN  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading in our data\n",
    "\n",
    "df = pd.read_csv('data/tweets_labeled.csv', header=0)\n",
    "\n",
    "# making sure dataset loaded in properly\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "152a5cbe-af4f-4e35-98a5-788a59c43244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1619, 14)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5c89cb73-3362-4cb1-93f4-d1341eb2ecf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'X Accounts', 'Post Link', 'Post Text', 'Label', 'Retweets',\n",
       "       'Comments', 'Likes', 'Bookmarks', 'Views', 'Quick Notes',\n",
       "       'Custom Reports', 'Workflow', 'Legislative Tracker'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0602c0ed-8e7f-4012-8482-ef8846cfbad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>X Accounts</th>\n",
       "      <th>Post Link</th>\n",
       "      <th>Post Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Bookmarks</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/8/2026</td>\n",
       "      <td>Nadia Rahman Èß±ÈõØ</td>\n",
       "      <td>https://x.com/nadiarahmansf/status/20091324931...</td>\n",
       "      <td>The defining moment of the first congressional...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1062.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>6318.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>355035.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/8/2026</td>\n",
       "      <td>John Guandolo</td>\n",
       "      <td>https://x.com/JGuandolo54271/status/2009080087...</td>\n",
       "      <td>@WallStreetApes Diyanet Center of America\\nISN...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/7/2026</td>\n",
       "      <td>Pamela Hensleyüá∫üá∏</td>\n",
       "      <td>https://x.com/i/status/2008756328928538637</td>\n",
       "      <td>There is an Iranian-run daycare in Los Angeles...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5571.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>34300.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>256927.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date        X Accounts  \\\n",
       "0  1/8/2026   Nadia Rahman Èß±ÈõØ   \n",
       "1  1/8/2026     John Guandolo   \n",
       "2  1/7/2026  Pamela Hensleyüá∫üá∏   \n",
       "\n",
       "                                           Post Link  \\\n",
       "0  https://x.com/nadiarahmansf/status/20091324931...   \n",
       "1  https://x.com/JGuandolo54271/status/2009080087...   \n",
       "2         https://x.com/i/status/2008756328928538637   \n",
       "\n",
       "                                           Post Text  Label  Retweets  \\\n",
       "0  The defining moment of the first congressional...    NaN    1062.0   \n",
       "1  @WallStreetApes Diyanet Center of America\\nISN...    NaN       3.0   \n",
       "2  There is an Iranian-run daycare in Los Angeles...    NaN    5571.0   \n",
       "\n",
       "   Comments    Likes  Bookmarks     Views  \n",
       "0     155.0   6318.0      532.0  355035.0  \n",
       "1       0.0     14.0        1.0     426.0  \n",
       "2     328.0  34300.0      324.0  256927.0  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing unnecessary columns\n",
    "\n",
    "df_clean = df.drop(columns=['Quick Notes', 'Custom Reports', 'Workflow', 'Legislative Tracker'])\n",
    "\n",
    "# making sure the columns were removed correctly\n",
    "\n",
    "df_clean.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "38d24d73-0a3e-49b9-b139-4c884f2da341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking to see if there are any null entries under the `Post Text` column\n",
    "\n",
    "df_clean['Post Text'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "985ee4db-0556-40f1-8f16-ecb67a5e11f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>X Accounts</th>\n",
       "      <th>Post Link</th>\n",
       "      <th>Post Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Bookmarks</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>7/16/2025</td>\n",
       "      <td>W H Y T E_R Y K</td>\n",
       "      <td>https://twitter.com/RealWhyteRyk/status/194551...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>5/23/2025</td>\n",
       "      <td>üîªüáÆüá∂üáµüá∏üá±üáßüáæüá™üá∞üáµüáÆüá∑üîª</td>\n",
       "      <td>https://x.com/notbasrairaqi2/status/1925890468...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>5/22/2025</td>\n",
       "      <td>‚ò≠ ü™Çüê∂ KarlüîªBarx üê∂ü™Ç‚ò≠</td>\n",
       "      <td>https://x.com/Karl_Barxxx/status/1925584865715...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6429.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>5/22/2025</td>\n",
       "      <td>julia üîªü™Ç</td>\n",
       "      <td>https://x.com/k1myojong/status/192560532264050...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5485.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>5/22/2025</td>\n",
       "      <td>descriptive display name that is way too long and</td>\n",
       "      <td>https://x.com/mrgracemugabe/status/19255601712...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>264200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>5/20/2025</td>\n",
       "      <td>Ihcen üîª</td>\n",
       "      <td>https://x.com/ihcentoo/status/1924981885576303047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>2/16/2025</td>\n",
       "      <td>SaltyGoy2083</td>\n",
       "      <td>https://x.com/goy208395235/status/189128417012...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date                                         X Accounts  \\\n",
       "1471  7/16/2025                                    W H Y T E_R Y K   \n",
       "1479  5/23/2025                                     üîªüáÆüá∂üáµüá∏üá±üáßüáæüá™üá∞üáµüáÆüá∑üîª   \n",
       "1501  5/22/2025                                 ‚ò≠ ü™Çüê∂ KarlüîªBarx üê∂ü™Ç‚ò≠   \n",
       "1502  5/22/2025                                           julia üîªü™Ç   \n",
       "1504  5/22/2025  descriptive display name that is way too long and   \n",
       "1505  5/20/2025                                            Ihcen üîª   \n",
       "1610  2/16/2025                                       SaltyGoy2083   \n",
       "\n",
       "                                              Post Link Post Text  Label  \\\n",
       "1471  https://twitter.com/RealWhyteRyk/status/194551...       NaN    NaN   \n",
       "1479  https://x.com/notbasrairaqi2/status/1925890468...       NaN    NaN   \n",
       "1501  https://x.com/Karl_Barxxx/status/1925584865715...       NaN    NaN   \n",
       "1502  https://x.com/k1myojong/status/192560532264050...       NaN    NaN   \n",
       "1504  https://x.com/mrgracemugabe/status/19255601712...       NaN    NaN   \n",
       "1505  https://x.com/ihcentoo/status/1924981885576303047       NaN    NaN   \n",
       "1610  https://x.com/goy208395235/status/189128417012...       NaN    NaN   \n",
       "\n",
       "      Retweets  Comments    Likes  Bookmarks     Views  \n",
       "1471       NaN       NaN      NaN        NaN       NaN  \n",
       "1479       1.0       0.0      0.0        0.0      35.0  \n",
       "1501      26.0       1.0    276.0        5.0    6429.0  \n",
       "1502      67.0       4.0    329.0       14.0    5485.0  \n",
       "1504    1300.0      40.0  17000.0      522.0  264200.0  \n",
       "1505      42.0       0.0    254.0       20.0    4473.0  \n",
       "1610       NaN       NaN      NaN        NaN       NaN  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seeing which rows have null values\n",
    "\n",
    "df_clean[df_clean[\"Post Text\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "08fbac9b-0005-4f4d-9d17-927c865edd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping rows with null values in `Post Text`\n",
    "\n",
    "df_clean = df_clean.dropna(subset=['Post Text']).copy()\n",
    "\n",
    "# making sure it worked\n",
    "\n",
    "df_clean['Post Text'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f7302a-a9b8-43b9-9244-9428088e9441",
   "metadata": {},
   "source": [
    "### `clean_tweet()` Text Preprocessing Function\n",
    "Now that we've removed null values under `Post Text` and unnecessary columns, next we need to clean the text we will be analyzing by handling hyperlinks and spelling errors.\n",
    "\n",
    "We will do this by creating a a **function for text preprocessing** called `clean_tweet`() to perform the following:\n",
    "- Lowercase text.\n",
    "- Replace URLs with \"URL\".\n",
    "- Replace @mentions with \"USER\".\n",
    "- Normalize quotes.\n",
    "- Removes extra whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a2b00b7a-4ce8-4990-b837-f998d8a4d010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(text):\n",
    "    \n",
    "    # lowercase everything so words are treated the same regardless of capitalization\n",
    "    text = text.lower()\n",
    "    \n",
    "    # standardizing quotation marks and apostrophes so text is consistent\n",
    "    text = text.replace(\"‚Äú\", '\"').replace(\"‚Äù\", '\"')\n",
    "    text = text.replace(\"‚Äô\", \"'\").replace(\"‚Äò\", \"'\")\n",
    "    \n",
    "    # replacing hyperlinks with the token \"URL\"\n",
    "    text = re.sub(r\"http\\S+|www\\.\\S+\", \" URL \", text)\n",
    "    \n",
    "    # replacing usernames with the token \"USER\"\n",
    "    text = re.sub(r\"@\\w+\", \" USER \", text)\n",
    "    \n",
    "    # removing hashtags \n",
    "    text = text.replace(\"#\", \"\")\n",
    "    \n",
    "    # replacing multiple spaces/white space with a single space and stripping extra spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4c01dadd-89df-413e-866a-6b2765f7da54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the function to every row in the `Post Text` column\\\n",
    "# and creating a new column that we will use for modeling\n",
    "df_clean['Clean Text'] = df_clean['Post Text'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9763e11a-8b87-47bc-974a-abaa63882b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>X Accounts</th>\n",
       "      <th>Post Link</th>\n",
       "      <th>Post Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Bookmarks</th>\n",
       "      <th>Views</th>\n",
       "      <th>Clean Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/8/2026</td>\n",
       "      <td>Nadia Rahman Èß±ÈõØ</td>\n",
       "      <td>https://x.com/nadiarahmansf/status/20091324931...</td>\n",
       "      <td>The defining moment of the first congressional...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1062.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>6318.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>355035.0</td>\n",
       "      <td>the defining moment of the first congressional...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/8/2026</td>\n",
       "      <td>John Guandolo</td>\n",
       "      <td>https://x.com/JGuandolo54271/status/2009080087...</td>\n",
       "      <td>@WallStreetApes Diyanet Center of America\\nISN...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>USER diyanet center of america isna uscmo icna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/7/2026</td>\n",
       "      <td>Pamela Hensleyüá∫üá∏</td>\n",
       "      <td>https://x.com/i/status/2008756328928538637</td>\n",
       "      <td>There is an Iranian-run daycare in Los Angeles...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5571.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>34300.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>256927.0</td>\n",
       "      <td>there is an iranian-run daycare in los angeles...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date        X Accounts  \\\n",
       "0  1/8/2026   Nadia Rahman Èß±ÈõØ   \n",
       "1  1/8/2026     John Guandolo   \n",
       "2  1/7/2026  Pamela Hensleyüá∫üá∏   \n",
       "\n",
       "                                           Post Link  \\\n",
       "0  https://x.com/nadiarahmansf/status/20091324931...   \n",
       "1  https://x.com/JGuandolo54271/status/2009080087...   \n",
       "2         https://x.com/i/status/2008756328928538637   \n",
       "\n",
       "                                           Post Text  Label  Retweets  \\\n",
       "0  The defining moment of the first congressional...    NaN    1062.0   \n",
       "1  @WallStreetApes Diyanet Center of America\\nISN...    NaN       3.0   \n",
       "2  There is an Iranian-run daycare in Los Angeles...    NaN    5571.0   \n",
       "\n",
       "   Comments    Likes  Bookmarks     Views  \\\n",
       "0     155.0   6318.0      532.0  355035.0   \n",
       "1       0.0     14.0        1.0     426.0   \n",
       "2     328.0  34300.0      324.0  256927.0   \n",
       "\n",
       "                                          Clean Text  \n",
       "0  the defining moment of the first congressional...  \n",
       "1  USER diyanet center of america isna uscmo icna...  \n",
       "2  there is an iranian-run daycare in los angeles...  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making sure the function worked properly\n",
    "\n",
    "df_clean.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5dcfad-a071-407e-a3b3-5edf03071440",
   "metadata": {},
   "source": [
    "#### With the whole data set cleaned up, we can start preparing ourselves for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2916ac-25a4-4763-a743-08af08f86eff",
   "metadata": {},
   "source": [
    "### Extracting Labeled Data\n",
    "\n",
    "As discussed above, only a smaller subset of the rows within the larger data set contain labels that we manually entered under the new column, `Label`, with a 0 indicating the tweet is not Islamophobic and a 1 indicating the tweet is Islamophobic.\n",
    "\n",
    "We now need to extract those labeled rows so that we can use them to train our classifier and perform our modeling. We will refer to this as `df_labeled`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "de64e7fc-35c6-425c-8ce8-aa74d09fd07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 11)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a new dataframe that contains only the labeled data from df_clean\n",
    "\n",
    "df_labeled = df_clean[df_clean['Label'].notna()].copy()\n",
    "\n",
    "# making sure it worked\n",
    "\n",
    "df_labeled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "71bc9748-e724-4cd5-b9f8-24a2685154ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    100\n",
       "1    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turning label values into integers\n",
    "df_labeled['Label'] = df_labeled['Label'].astype(int)\n",
    "\n",
    "df_labeled['Label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d96758c-e124-4035-9209-728843e2dcde",
   "metadata": {},
   "source": [
    "### Splitting the Data\n",
    "\n",
    "Next, we will split our data into Training and Testing sets to use in our pipelines later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7fceb6cf-7679-4e57-a738-5fe4a711144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating our X (features) and y (target) \n",
    "\n",
    "X = df_labeled['Clean Text']  \n",
    "y = df_labeled'\"Label']        \n",
    "\n",
    "# creating the Train-Test Splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y # making sure the sets have the same class balance\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db08a60-6f5c-4c77-8827-8506188e34fb",
   "metadata": {},
   "source": [
    "# III. Data Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8711fda-3d86-4ef2-b24d-b425fab040b3",
   "metadata": {},
   "source": [
    "Now that our data is preprocessed and our Training and Testing sets are ready, we'll start constructing our modeling pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aa4c35-c532-43d7-b35e-a305fed863f6",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b77d83-c486-4498-bccf-78844f2c5b17",
   "metadata": {},
   "source": [
    "As discussed earlier, we will be creating two model pipelines:\n",
    "1. `Logistic Regression` with TF-IDF Vectorizer\n",
    "2. `LinearSVM` with TF-IDF Vectorizer\n",
    "\n",
    "As a reminder, we are aiming to maximize **Precision** as our primary metric (and will consider the Recall score as supplementary), so we will tune the pipeline's parameters accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9a922485-5719-4c04-94c6-79c18f7c5354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the Logistic Regression + TF-IDF pipeline\n",
    "logreg_pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        ngram_range=(1,2),      # include bigrams\n",
    "        min_df=2,               # exclude words that only appear once\n",
    "        max_df=0.95             # exclude words that are too common\n",
    "    )), \n",
    "    (\"clf\", LogisticRegression(\n",
    "        max_iter=2000, \n",
    "        class_weight=\"balanced\"\n",
    "    )) \n",
    "])\n",
    "\n",
    "# creating the Linear SVM + TF-IDF pipeline\n",
    "svm_pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        ngram_range=(1,2), \n",
    "        min_df=2, \n",
    "        max_df=0.95\n",
    "    )),\n",
    "    (\"clf\", LinearSVC(\n",
    "        class_weight=\"balanced\"\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "38784438-da9c-4ed2-9b66-aeb9dad82013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogReg\n",
      "Precision: 0.900\n",
      "Recall:    0.900\n",
      "\n",
      "LinearSVM\n",
      "Precision: 0.864\n",
      "Recall:    0.950\n"
     ]
    }
   ],
   "source": [
    "# creating for loop to fit and run the models and provide metric scores\n",
    "models = {\n",
    "    \"LogReg\": logreg_pipe,\n",
    "    \"LinearSVM\": svm_pipe\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    precision = precision_score(y_test, preds)\n",
    "    recall = recall_score(y_test, preds)\n",
    "\n",
    "    print(f\"\\n{name}\")\n",
    "    print(f\"Precision: {precision:.3f}\")\n",
    "    print(f\"Recall:    {recall:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9aa19d-97e8-423e-99b0-7f44f735a504",
   "metadata": {},
   "source": [
    "These are **excellent** scores. \n",
    "\n",
    "90% of the tweets classified as Islamophobic by the `Logistic Regression` model were actually Islamophobic, and it successfully caught 90% of Islamophobic tweets.\n",
    "\n",
    "In comparison, the `LinearSVM` model let a few more False Positives slip by, however it let 5% fewer Islamophobic tweets slip through the cracks.\n",
    "\n",
    "It tells us that both models successfully kept the vast majority of False Positives out of the Islamophobic tweets bucket, and each only missed a few Islamophobic tweets that it mistakenly marked as not Islamophobic.\n",
    "\n",
    "However, these scores may be too good to be true, and could be due to our relatively small collection of labeled tweets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07589b0c-1908-4443-a62c-80e8a2dfc732",
   "metadata": {},
   "source": [
    "### Cross-Validation \n",
    "\n",
    "Since our labeled tweets were relatively small, numbering only 200, a single train-test split can give us misleading results, depending on how the data was split.\n",
    "\n",
    "To increase our confidence in these models, we will add a **cross-validation** component to the pipelines and run them again, so we can be more sure of the models' competence when applying them to the wider dataset, as cross-validation can give more reliable estimates of how well the models perform across various data splits.\n",
    "\n",
    "We will use `Stratified K-Fold` to create 5, equally balanced splits, or folds, of the data, and compare the models' performances across those 5 folds using standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e7060bb9-2c11-4c00-9c55-1a1b7515d3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogReg\n",
      "Precision Score: 0.822 ¬± 0.063\n",
      "Recall Score:    0.830 ¬± 0.068\n",
      "\n",
      "LinearSVM\n",
      "Precision Score: 0.865 ¬± 0.050\n",
      "Recall Score:    0.870 ¬± 0.068\n"
     ]
    }
   ],
   "source": [
    "# setting up our cross-validation sets using Stratified K-Folds\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# creating for loop to run cross-validation through our model pipelines\n",
    "for name, model in models.items():\n",
    "    metrics = cross_validate(\n",
    "        model,\n",
    "        X,\n",
    "        y,\n",
    "        cv = cv,\n",
    "        scoring = ['precision', 'recall']\n",
    "    )\n",
    "\n",
    "    precision_cv = metrics['test_precision']\n",
    "    recall_cv = metrics['test_recall']\n",
    "\n",
    "    # printing metrics across the folds with standard deviation\n",
    "    print(f'\\n{name}')\n",
    "    print(f'Precision Score: {precision_cv.mean():.3f} ¬± {precision_cv.std():.3f}')\n",
    "    print(f'Recall Score:    {recall_cv.mean():.3f} ¬± {recall_cv.std():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e4d292-8c38-46b4-a63d-0dc8671db0c2",
   "metadata": {},
   "source": [
    "As expected, cross-validation placed more scrutiny on our models' performances.\n",
    "\n",
    "`Logistic Regression` created a more contaminated bucket of Islamophobic tweets, as it let an average of about 18% of False Positives. It also let an average of 17% of Islamophobic tweets slip through the cracks.\n",
    "\n",
    "In comparison, `LinearSVM` on average produced slightly less contaminated buckets of Islamophobic tweets with a rate of 13% of False Positives. It was also more successful in preventing False Negatives, meaning let only let 13% of Islamophobic tweets slip through the cracks.\n",
    "\n",
    "The `LinearSVM` model performed slightly better, so we will use it to classify the wider dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417444fb-e33f-4999-81de-213fb4c51873",
   "metadata": {},
   "source": [
    "### Classifying the Whole Dataset\n",
    "\n",
    "Since our models are effective at minimizing False Positives, we can move ahead and use the `LinearSVM` model (since it had a slightly higher Recall Score) to classify the entire dataset. We'll have the model add a column to the entire dataset called `pred_label` which will indicate the tweet's classification. Then we'll pull the tweets identified as Islamophobic into a new dataframe, `df_anti_islam`.\n",
    "\n",
    "Then we'll be able to move forward with extracting themes via Topic Modeling from the collection of tweets classified as Islamophobic.\n",
    "\n",
    "Though we've established that our models are strong through cross-validation, we'll take an extra measure of caution and factor in our model's confidence in its classification using the model's `decision_function`, which gives a relative confidence metric. We'll focus on using the classified tweets that the model is relatively confident about by adding in a column in the dataframe `conf_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bf195987-bf9e-4eef-826b-438c70a30ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pred Label\n",
       "1    859\n",
       "0    753\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the model pipeline on entire labeled data set\n",
    "svm_pipe.fit(X, y)\n",
    "\n",
    "# using the model to predict the entire unlabeled dataset and adding results to a new column\n",
    "df_clean['Pred Label'] = svm_pipe.predict(df_clean['Clean Text'])\n",
    "\n",
    "# creating a column with the degree of the model's confidence in the classification\n",
    "df_clean['Conf Score'] = svm_pipe.decision_function(df_clean['Clean Text'])\n",
    "\n",
    "# checking the model's classification results\n",
    "\n",
    "df_clean['Pred Label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae265b02-7bfc-4254-a6c6-99b7880a3d1d",
   "metadata": {},
   "source": [
    "According to our trained `LinearSVM` model, our entire dataset contains:\n",
    "- 859 Islamophobic Tweets (53%)\n",
    "- 753 not Islamophobic Tweets (47%)\n",
    "\n",
    "Let's extract the Islamophobic tweets with higher degrees of confidence from the model into a new dataframe, `df_anti-Islam`, and we can use this to investigate themes and topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1f026fa4-cf6f-417c-9af8-693bed2345f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(458, 13)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pulling high confidence Islamophobic tweets\n",
    "df_anti_islam = df_clean[df_clean['Conf Score'] >= 0.3].copy()\n",
    "\n",
    "# checking how many tweets we pulled\n",
    "df_anti_islam.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c497f1-a29d-46d5-ab30-d39fe9b1c080",
   "metadata": {},
   "source": [
    "So we have a total of about 458 tweets to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4593b2eb-886c-4a67-b8b6-7e6d1ff10451",
   "metadata": {},
   "source": [
    "## Topic Modeling \n",
    "\n",
    "With the 458 tweets we've confidently classified as Islamophobic in `df_anti_islam`, we can move to topic modeling, which can help us glean recurring themes based on the text contained in the dataset.\n",
    "\n",
    "We'll use engagement metrics within the dataset, namely Likes and Retweets, as weights to help our topic modeling decipher which types of rhetoric gains more traction.\n",
    "\n",
    "It should be noted that relative Likes and Retweets do not only correlate to salient rhetoric, but also reflects other factors like the posting accounts following and reach. So rather than conclude that \"X rhetoric leads to higher engagement\", it would be more accurate to frame our findings as \"X rhetoric is **receiving higher engagement**\".\n",
    "\n",
    "We'll again use `TF-IDF` as our vectorizer, this time to pull out most recurring words.\n",
    "\n",
    "To extract themes, we will feed the vectors created by `TF-IDF()` into a Truncated Singular Value Decomposition (`TruncatedSVD()`) model, due to its ability to process sparse data efficiently. Then we can use `KMeans()` to create clusters out of those modeled vectors, allowing us to see which terms cluster together and learn which themes can be gleaned from the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "d6b18b1c-108a-4610-ac60-d673ce1041ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizing our text\n",
    "tfidf = TfidfVectorizer(\n",
    "    ngram_range=(1,2), \n",
    "    min_df=2, \n",
    "    max_df=0.90\n",
    ")\n",
    "X = tfidf.fit_transform(df_anti_islam['Clean Text'])\n",
    "\n",
    "# feeding data into SVD model\n",
    "svd = TruncatedSVD(\n",
    "    n_components=50, \n",
    "    random_state=42\n",
    ")\n",
    "X_svd = svd.fit_transform(X)\n",
    "\n",
    "# filtering the data into 5 clusters\n",
    "kmeans = KMeans(\n",
    "    n_clusters=5, \n",
    "    random_state=42, \n",
    "    n_init='auto'\n",
    ")\n",
    "df_anti_islam['Theme'] = kmeans.fit_predict(X_svd)\n",
    "\n",
    "# pulling the themes out\n",
    "terms = tfidf.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a55da12-3cd5-4892-854a-54601192ce77",
   "metadata": {},
   "source": [
    "Next we'll run a for loop to display the major themes and top related words underneath each theme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "31f9ede0-3227-45d7-9824-2d5330653e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "THEME 0\n",
      "to, islam, is, we, america, url, the, it, and, our, islam is, be, deport, in, from, sharia, needs to, not, needs, this, need, every, sharia law, america url, no, of, to be, law, must, has\n",
      "\n",
      "THEME 1\n",
      "the, and, texas, is, islamic, this, to, sharia, in, of, epic, are, it, city, not, they, this is, he, that, just, epic city, their, for, you, mosque, isn, in texas, about, qadhi, with\n",
      "\n",
      "THEME 2\n",
      "the, of, in, to, is, url, and, dearborn, are, islam, for, they, america, it, will, we, on, this, islamic, texas, in the, of the, muslims, muslim, that, have, be, our, people, michigan\n",
      "\n",
      "THEME 3\n",
      "brotherhood, muslim brotherhood, terrorist, terrorist organization, organization, the muslim, the, muslim, cair, as, as terrorist, and, to, user, url, brotherhood as, designated, designate, foreign, designating, foreign terrorist, is, trump, as foreign, designated as, president, be, president trump, designation, executive order\n",
      "\n",
      "THEME 4\n",
      "islamization of, the islamization, islamization, of america, costs url, all costs, at all, america, costs, of, and america, put, must, at, we, the, all, texas and, of texas, put an, america immediately, end to, an end, immediately url, url, texas, we must, continues, immediately, we cannot\n"
     ]
    }
   ],
   "source": [
    "for t in sorted(df_anti_islam['Theme'].unique()):\n",
    "    idx = df_anti_islam['Theme'] == t\n",
    "    mean_tfidf = X[idx].mean(axis=0)\n",
    "    top_idx = np.asarray(mean_tfidf).ravel().argsort()[-30:][::-1]\n",
    "\n",
    "    print(f\"\\nTHEME {t}\")\n",
    "    print(\", \".join([terms[i] for i in top_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80997554-efcc-4ad2-a389-a2654d808142",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562b2df6-9c34-4590-8e1d-7949c780a2fc",
   "metadata": {},
   "source": [
    "Based on the themes clustered above, we can understand a number of trends occurring in Islamophobic discourse right now. Let's take a moment to evaluate what these Themes might tell us, and if they are useful at all. \n",
    "- **Theme 0**: vague; we can perhaps conclude that this theme deals with fear of Sharia law in the US, though it's inconclusive.\n",
    "- **Theme 1**: we can conclude that there is heightened interest and attention on Texas, where Islamophobic personalities have stirred tensions around the growing Muslim population and a perceived increase in mosques. Tellingly, this cluster reflects an agitation against the the [East Plano Islamic Center (EPIC) City](https://en.wikipedia.org/wiki/EPIC_City,_Texas) project, which is a master-planned Islamic community-centered residential project in Texas. Yasir Qadhi, an Islamic scholar affiliated with Dallas-based Qalam Institute, seems to feature prominently in this theme.\n",
    "- **Theme 2**: similar to Theme 1, this cluster appears to be concerned with a particular locale, being Dearborn, MI, known for its high concentration of Muslim and Arab residents. The presence of \"Texas\" here may indicate that many are drawing connections between the two sites, though we'd have to investigate further to confirm this and the nature of these connections.\n",
    "- **Theme 3**: This may be the only explicitly political theme among these clusters, indicating an increased interest in the Muslim Brotherhood as well as fear of its alleged presence and activity in the US. The presence of CAIR (which the the Council on American Islamic Relations) in this cluster may confirm this conclusion considering recent moves by the Governors of Florida and Texas to impose restrictions on CAIR activity under the allegation of its connection to the Muslim Brotherhood.\n",
    "- **Theme 4**: This reflects a more general concern with perceived Islamization of the US. The presence of \"Texas\" yet again may further confirm heightened attention around Texas specifically as what Islamophobes posit as a battleground of site of struggle against the alleged Islamization of America.\n",
    "\n",
    "Now that we have more of a grasp on what these themes represent in public discourse, we can try to measure the salience of each of these themes within Islamophobic discourse online. We'll do so by plotting the relative engagement tweets within each theme received in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "7b10080f-b7ca-4698-b9c4-877b47150b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating Engagement metric column\n",
    "df_anti_islam['Engagement'] = (\n",
    "    df_anti_islam['Likes'].fillna(0) +\n",
    "    df_anti_islam['Retweets'].fillna(0)\n",
    ")\n",
    "\n",
    "# grouping themes by relative engagement\n",
    "theme_stats = (\n",
    "    df_anti_islam.groupby('Theme')['Engagement']\n",
    "    .agg(count = 'count', total='sum', average='mean')\n",
    "    .sort_values('total', ascending=False)\n",
    ")\n",
    "\n",
    "# plotting themes according to engagement\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(theme_stats.index.astype(str), theme_stats['total'])\n",
    "plt.title('Total Engagement by Theme')\n",
    "plt.xlabel('Theme')\n",
    "plt.ylabel('Total Engagement')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366c0874-fa24-4538-ba97-b34d3b82e0d8",
   "metadata": {},
   "source": [
    "Here's what this graph tells us:\n",
    "1. The top two themes with the most engagement are the two themes dealing with specific locales. There is by far the most engagement with Theme 2, which deals with Dearborn, MI and potentially draws connection to Texas. The second most prominent theme is Theme 1, which deals with Texas directly and the proposed EPIC City project.\n",
    "2. The third-most engaged theme is Theme 0, that we found to be more vague and are hypothesizing reflects a more general fear of Sharia Law in the US.\n",
    "3. There is a growing fear of the Muslim Brotherhood in the US, which has become more of a salient talking point among the Islamophobic Right. Experience tells us that often times, concern with Muslim Brotherhood presence is rooted in a projected fear of actors in the Middle East and international politics more generally, and the presence of CAIR in this theme indicates that attempts to connect the civil rights organization to international actors may be resonating with some figures and the public. The explicitly poltiical nature of this theme, that it is centered around a political organization, can lead us to conclude that geopolitical developments in the Middle East over the past two plus years has had some sort of impact on Islamophobic discourse. We would have to investigate this to better unpack the theme and its significance.\n",
    "4. Theme 4, dealing with general fear of Islamization, appears to have the least engagement. This could lead us to believe that Islamophobic discourse centered around a kinetic situation posits more immediate stakes and therefore receives more engagement, or that prominent online figures choose to focus their rhetoric around these kinetic situations. We would need to investigate further to better understand this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ea7312-2432-487c-aaff-846fec41b331",
   "metadata": {},
   "source": [
    "# IV. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f4b009-30b4-47a7-b7ee-ed8b9981eebc",
   "metadata": {},
   "source": [
    "We were tasked with better understanding the salient and prominent currents fueling Islamophobic rhetoric online. To do this, we were given a dataset containing 1,619 tweets that expressed some sort of hateful or extreme ideas.\n",
    "\n",
    "We understood that the nature of our mission in this investigation made False Positives more msotly than False Negatives, as we wanted to minimize potential contamination of our analysis of Islamophobic tweets, placing primary importance on **Precision** as a metric of success.\n",
    "\n",
    "We utilized this dataset to conduct the following investigation:\n",
    "1. Manually labeled a sample of 200 tweets, half containing non-Islamophobic tweets and half containing Islamophobic tweets.\n",
    "2. Trained binary classifiers on this subset with the assistance of `TF-IDF()` and evaluated their performance according to Precision as a primary metric and Recall as a secondary metric, and used `cross-validation` to confirm the success of these models.\n",
    "3. Applied the more successful trained model, `LinearSVD()`, on the entire unlabeled dataset, and split all tweets into buckets of Islamophic and non-Islamophobic tweets. We also used the `decision_function` within the classifier to attribute relative confidence scores for the classifications.\n",
    "4. Pulled the tweets labeled Islamophobic by the classifier with relatively higher degrees of confidence, numbering 458 tweets total.\n",
    "5. Vectorized those 458 Islamophobic tweets using `TF-IDF` and ran those vectors into `TruncatedSVD()` to capture patterns in the data.\n",
    "6. Used Topic Modeling via `KMeans()` to cluster those patterns and grouping commonly used and related terms into Themes.\n",
    "7. Ranked the relative salience and impact of each of those Themes by creating a visualization that used 'Likes' and 'Retweet' metrics in the dataset as proxies for levels of engagement, and displayed the engagement that each Theme received.\n",
    "\n",
    "### Evaluating Success Criteria\n",
    "At the outset of this investigation, we laid out three questions with which we intended to evaluated the investigation's results. We will repeat them here and respond according to our output:\n",
    "**1. Is the classifier functional and reliable enough to support triage?**\n",
    "\n",
    "- Answer: While the classifier is functional within the confines of this particular project, **we cannot confidently assert that our classifier is sufficiently equipped for general application and triage**. This is mainly due to limitations pertaining to the dataset itself, which will be elaborated upon in the Limitations section below.\n",
    "\n",
    "**2. Did we learn something real, clear, and repeatable about the discourse?**\n",
    "\n",
    "- Answer: **Yes**, we were able to ascertain tangible themes contained within the dataset that reflect prominent currents in Islamophobic rhetoric posted and amplified on social media.\n",
    "\n",
    "**3. Can the insights inform real decisions?**\n",
    "\n",
    "- Answer: **Yes**, we were able to utilize wider contextual understanding of recent developments and trends rooted in domain knowledge to understand social and political causes animating major currents in Islamophobic discourse, and can effectively use this deeper understanding to inform recommendations to interested actors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2436db86-bc61-4858-8cdd-ba21c92dbfd3",
   "metadata": {},
   "source": [
    "## Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1349df-046a-4c4b-b531-3d6fa2240d94",
   "metadata": {},
   "source": [
    "Since we were not in control of how the data was collected, there are a number of limitations on our investigation arising from the dataset:\n",
    "1. We do not know the degree of its veracity or how representative it is. For example, is the prevalence of tweets pertaining to Dearborn and Texas due to their current salience in the moment? Or was the creator of the dataset specifically looking to capture discourse on those two sites of tension?\n",
    "2. There is an imbalance in the dates the tweets were collected: we can't know if the reason there are far more Islamophobic tweets in 2025 than in 2023 is due to a surge in Islamophobia, or due to the timing of when/how the dataset was collected.\n",
    "3. There is an outsized presence of a handful of virulent Islamophobic personalities, such as Amy Menk or Laura Loomer, which more than likely skewed our classifier's ability to understand the nuances of Islamophobic discourse. Is it that these handful of figures are the driving forces of Islamophobic discourse, or was the creator the dataset intentionally keeping a close eye on them?\n",
    "4. Many of the tweets contained photos with text that was not transcribed, so we were unable to factor in the language used on those photos in our modeling.\n",
    "\n",
    "Furthermore, our decision to zero in on a strict definition of Islamophobia allowed us to be more focused in our modeling, but most likely caused us to miss more nuanced topics:\n",
    "1. To what extent is a xenophobic fear of certain immigrant communities tied to Islamophobia?\n",
    "2. In what ways does more subtle forms of Islamophobia inform opinions on international matters?\n",
    "\n",
    "number of clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d84cd8-fe33-4452-a81b-f7a31cc9927e",
   "metadata": {},
   "source": [
    "## Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e860e9-c39c-48dc-9a57-a387d5d27b3a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c80c11c1-0056-452c-bd70-ecde66b57769",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb772f7-1a7e-4f8f-a0ae-0cb24a71c6b5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
